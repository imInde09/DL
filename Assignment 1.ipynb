{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LP-IV Assignment 1"],"metadata":{"id":"s-J3hUqzenIV"}},{"cell_type":"markdown","source":["### Title of Assignment 1 :-\n","Study of Deep learning Packages: Tensorflow, Keras, Theano and PyTorch. Document the distinct features and functionality of the packages."],"metadata":{"id":"nhpgRgO5ereF"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpE9yYHFeor9","executionInfo":{"status":"ok","timestamp":1669084390804,"user_tz":-330,"elapsed":2905,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"39470aa0-7f3f-48e6-ace9-0b6af76d9e41"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.9.2\n"]}]},{"cell_type":"code","source":["msg = tf.constant('Hello, TensorFlow!')\n","tf.print(msg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cj2rMojeeouc","executionInfo":{"status":"ok","timestamp":1669084393356,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"0971aa2e-ac97-40ec-db10-191b8a78d117"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, TensorFlow!\n"]}]},{"cell_type":"code","source":["import keras\n","print(\"Keras version:\", keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYghNfPgeoxf","executionInfo":{"status":"ok","timestamp":1669084396574,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"fec8e9ed-f185-42a9-aeec-6d6f89ab05fd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Keras version: 2.9.0\n"]}]},{"cell_type":"code","source":["from keras import datasets\n","from keras import models\n","from keras import layers\n","from keras.utils import to_categorical"],"metadata":{"id":"6mDIxgkoeo0N","executionInfo":{"status":"ok","timestamp":1669084399013,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load MNIST data\n","mnist = tf.keras.datasets.mnist\n","#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Cui-0xdeo3E","executionInfo":{"status":"ok","timestamp":1669084401338,"user_tz":-330,"elapsed":481,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"eff53634-724a-4f00-dd81-0eabba068e8f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Create network comprising of two dense (fully connected) layers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), name=\"layer1\"))\n","network.add(layers.Dense(10, activation='softmax', name=\"layer2\"))"],"metadata":{"id":"el5_Kuxje-Ss","executionInfo":{"status":"ok","timestamp":1669084405238,"user_tz":-330,"elapsed":453,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Prepare the training images and training labels\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype('float32') / 255\n","train_labels = to_categorical(train_labels)"],"metadata":{"id":"dzRJfl1ze-V4","executionInfo":{"status":"ok","timestamp":1669084406775,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Prepare the test images and test labels\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype('float32') / 255\n","test_labels = to_categorical(test_labels)"],"metadata":{"id":"JUhpR4cte-bo","executionInfo":{"status":"ok","timestamp":1669084409127,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Prepare the network\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"metadata":{"id":"ma8ttI7Geo5s","executionInfo":{"status":"ok","timestamp":1669084411019,"user_tz":-330,"elapsed":1,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Fit the neural network\n","network.fit(train_images, train_labels, epochs=5, batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h2Po0vyWfFqq","executionInfo":{"status":"ok","timestamp":1669084429516,"user_tz":-330,"elapsed":15203,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"712830b9-be7b-4e40-c392-9a0fdc79a978"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2546 - accuracy: 0.9262\n","Epoch 2/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1047 - accuracy: 0.9691\n","Epoch 3/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0684 - accuracy: 0.9794\n","Epoch 4/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0492 - accuracy: 0.9852\n","Epoch 5/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0374 - accuracy: 0.9891\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7a840d1450>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Evaluate the network performance\n","test_loss, test_acc = network.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35NrE6xPfH4V","executionInfo":{"status":"ok","timestamp":1669084434484,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"5ff86668-1eeb-4dde-a71e-e1f0c4efbc96"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9799\n"]}]},{"cell_type":"code","source":["# Print the accuracy\n","print('test_acc:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mr7XH8PFenmO","executionInfo":{"status":"ok","timestamp":1669084436247,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"463e9e9b-bad2-44d3-ee12-b2138aeb5acd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["test_acc: 0.9799000024795532\n"]}]},{"cell_type":"code","source":["import torch as t\n","import torchvision.datasets as datasets \n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import matplotlib.pyplot as plt"],"metadata":{"id":"QbTZD03KgBK3","executionInfo":{"status":"ok","timestamp":1669084441158,"user_tz":-330,"elapsed":3024,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch\n","import math\n","\n","\n","# Create Tensors to hold input and outputs.\n","x = torch.linspace(-math.pi, math.pi, 2000)\n","y = torch.sin(x)\n","\n","# For this example, the output y is a linear function of (x, x^2, x^3), so\n","# we can consider it as a linear layer neural network. Let's prepare the\n","# tensor (x, x^2, x^3).\n","p = torch.tensor([1, 2, 3])\n","xx = x.unsqueeze(-1).pow(p)\n","\n","# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n","# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n","# of shape (2000, 3) \n","\n","# Use the nn package to define our model as a sequence of layers. nn.Sequential\n","# is a Module which contains other Modules, and applies them in sequence to\n","# produce its output. The Linear Module computes output from input using a\n","# linear function, and holds internal Tensors for its weight and bias.\n","# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n","# to match the shape of `y`.\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(3, 1),\n","    torch.nn.Flatten(0, 1)\n",")\n","\n","# The nn package also contains definitions of popular loss functions; in this\n","# case we will use Mean Squared Error (MSE) as our loss function.\n","loss_fn = torch.nn.MSELoss(reduction='sum')\n","\n","learning_rate = 1e-6\n","for t in range(2000):\n","\n","    # Forward pass: compute predicted y by passing x to the model. Module objects\n","    # override the __call__ operator so you can call them like functions. When\n","    # doing so you pass a Tensor of input data to the Module and it produces\n","    # a Tensor of output data.\n","    y_pred = model(xx)\n","\n","    # Compute and print loss. We pass Tensors containing the predicted and true\n","    # values of y, and the loss function returns a Tensor containing the\n","    # loss.\n","    loss = loss_fn(y_pred, y)\n","    if t % 100 == 99:\n","        print(t, loss.item())\n","\n","    # Zero the gradients before running the backward pass.\n","    model.zero_grad()\n","\n","    # Backward pass: compute gradient of the loss with respect to all the learnable\n","    # parameters of the model. Internally, the parameters of each Module are stored\n","    # in Tensors with requires_grad=True, so this call will compute gradients for\n","    # all learnable parameters in the model.\n","    loss.backward()\n","\n","    # Update the weights using gradient descent. Each parameter is a Tensor, so\n","    # we can access its gradients like we did before.\n","    with torch.no_grad():\n","        for param in model.parameters():\n","            param -= learning_rate * param.grad\n","\n","# You can access the first layer of `model` like accessing the first item of a list\n","linear_layer = model[0]\n","\n","# For linear layer, its parameters are stored as `weight` and `bias`.\n","print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a22Jz0WzgdUZ","executionInfo":{"status":"ok","timestamp":1669084443879,"user_tz":-330,"elapsed":1192,"user":{"displayName":"Kushal Choudhary","userId":"02982411221735689184"}},"outputId":"0b984906-7e44-4229-cb90-e62f897c3681"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["99 585.72314453125\n","199 391.6294860839844\n","299 262.8953857421875\n","399 177.49411010742188\n","499 120.82733154296875\n","599 83.21826171875\n","699 58.25145721435547\n","799 41.67294692993164\n","899 30.66162872314453\n","999 23.345613479614258\n","1099 18.483427047729492\n","1199 15.250978469848633\n","1299 13.101244926452637\n","1399 11.671045303344727\n","1499 10.719199180603027\n","1599 10.08541488647461\n","1699 9.663262367248535\n","1799 9.381922721862793\n","1899 9.19434928894043\n","1999 9.069217681884766\n","Result: y = 0.006716693751513958 + 0.8425942063331604 x + -0.001158741768449545 x^2 + -0.09131816029548645 x^3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3D6v700RgdXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ow5KnKF4gdaY"},"execution_count":null,"outputs":[]}]}